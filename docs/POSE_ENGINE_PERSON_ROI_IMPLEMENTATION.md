# PoseEngine Person ROI æ”¯æŒ - å®æ–½å®Œæˆ

> **å®æ–½æ—¥æœŸ**: 2025-01-21
> **ç›®æ ‡**: è®© PoseEngine æ¥å£æ”¯æŒå¤–éƒ¨æä¾›çš„ person_roiï¼Œå®Œå…¨å®ç°"æ‰€æœ‰æ¨¡å—åˆ†æåŒä¸€ä¸»è§’"

---

## ğŸ“‹ æ¦‚è¿°

æœ¬æ¬¡å®æ–½å®Œæˆäº† **PoseEngine å¤–éƒ¨ ROI æ”¯æŒ**ï¼Œä½¿å§¿æ€æ£€æµ‹æ¨¡å—èƒ½å¤Ÿä½¿ç”¨ç”± Face-Person å…³è”æä¾›çš„ person_roiï¼Œç¡®ä¿æƒ…ç»ªã€ç–²åŠ³ã€å§¿æ€ä¸‰ä¸ªæ¨¡å—åˆ†æçš„æ˜¯**å®Œå…¨ç›¸åŒçš„ä¸»è§’**ã€‚

### å®æ–½å‰åå¯¹æ¯”

#### å®æ–½å‰ âŒ

```
Face-Person å…³è” â†’ ä¸»è§’é€‰æ‹© â†’ æå– face_roi + person_roi
    â†“
æƒ…ç»ªæ¨¡å— â† face_roi (ä¸»è§’A)
ç–²åŠ³æ¨¡å— â† face_roi (ä¸»è§’A)
å§¿æ€æ¨¡å— â† è‡ªå·±æ£€æµ‹äººä½“ (å¯èƒ½æ£€æµ‹åˆ°èƒŒæ™¯äººå‘˜B) âš ï¸ ä¸ä¸€è‡´!
```

**é—®é¢˜**: å§¿æ€æ¨¡å—ç‹¬ç«‹æ£€æµ‹ personï¼Œå¯èƒ½æ£€æµ‹åˆ°ä¸åŒçš„äººï¼Œå¯¼è‡´ç»“æœä¸ä¸€è‡´ã€‚

#### å®æ–½å âœ…

```
Face-Person å…³è” â†’ ä¸»è§’é€‰æ‹© â†’ æå– face_roi + person_roi
    â†“
æƒ…ç»ªæ¨¡å— â† face_roi (ä¸»è§’A)
ç–²åŠ³æ¨¡å— â† face_roi (ä¸»è§’A)
å§¿æ€æ¨¡å— â† person_roi (ä¸»è§’A) âœ… ä½¿ç”¨ç›¸åŒçš„ person!
```

**ä¼˜åŠ¿**: æ‰€æœ‰æ¨¡å—åˆ†æåŒä¸€ä¸ªä¸»è§’ï¼Œç»“æœä¸€è‡´æ€§æœ‰ä¿éšœã€‚

---

## ğŸ”§ ä¿®æ”¹å†…å®¹

### 1. PoseEngine æ¥å£å¢å¼º

**æ–‡ä»¶**: `modules/engines/pose_engine.py`

#### ä¿®æ”¹ 1: `maybe_infer()` æ–¹æ³•ç­¾å

```python
def maybe_infer(
    self,
    rgb_frame,
    depth_frame,
    face_present: bool,
    global_frame_interval: float,
    frame_count: int,
    global_fps: float,
    person_roi=None,  #  æ–°å¢å‚æ•°
    person_bbox: Optional[Dict[str, int]] = None  #  æ–°å¢å‚æ•°
) -> PoseResult:
```

#### ä¿®æ”¹ 2: `_run_inference()` æ–¹æ³•

**æ–°å¢é€»è¾‘**: æ”¯æŒä¸¤ç§æ£€æµ‹æ¨¡å¼

```python
def _run_inference(
    self,
    rgb_frame,
    depth_frame,
    pose_age_ms: float,
    global_frame_interval: float,
    frame_count: int,
    global_fps: float,
    person_roi=None,  #  æ–°å¢å‚æ•°
    person_bbox: Optional[Dict[str, int]] = None  #  æ–°å¢å‚æ•°
) -> PoseResult:
```

**æ£€æµ‹é€»è¾‘**:

```python
# 1. æ£€æµ‹ 2D å…³é”®ç‚¹
#  æ”¯æŒå¤–éƒ¨æä¾›çš„ person_roiï¼ˆFace-Person å…³è”åœºæ™¯ï¼‰
if person_roi is not None and hasattr(person_roi, 'roi_rgb'):
    # æ¨¡å¼ 1: ä½¿ç”¨å¤–éƒ¨æä¾›çš„ person ROIï¼ˆç¡®ä¿åˆ†æåŒä¸€ä¸»è§’ï¼‰
    detection_frame = person_roi.roi_rgb
    use_roi_mode = True
    roi_offset_x = person_bbox.get('x1', 0) if person_bbox else 0
    roi_offset_y = person_bbox.get('y1', 0) if person_bbox else 0
else:
    # æ¨¡å¼ 2: ä¼ ç»Ÿæ¨¡å¼ï¼ˆåœ¨å…¨å¸§ä¸Šç‹¬ç«‹æ£€æµ‹ï¼‰
    detection_frame = rgb_frame
    use_roi_mode = False
    roi_offset_x = 0
    roi_offset_y = 0

raw_pose = self.pose_detector.detect_posture_with_yolo(detection_frame)
```

**åæ ‡å˜æ¢**:

```python
# 2. æå–å…³é”®ç‚¹å’Œè´¨é‡æ ‡å¿—
keypoints_2d = self.pose_detector.filter_keypoints_only(raw_pose)
quality_flags = self.pose_detector.extract_quality_flags(raw_pose)

#  åæ ‡å˜æ¢ï¼šå¦‚æœä½¿ç”¨ ROI æ¨¡å¼ï¼Œéœ€è¦å°†åæ ‡è½¬æ¢å›å…¨å¸§åæ ‡ç³»
if use_roi_mode and (roi_offset_x != 0 or roi_offset_y != 0):
    keypoints_2d = {
        kp_name: (x + roi_offset_x, y + roi_offset_y)
        for kp_name, (x, y) in keypoints_2d.items()
    }
```

---

### 2. InferenceTask æ•°æ®ç»“æ„å¢å¼º

**æ–‡ä»¶**: `modules/core/async_engine.py`

```python
@dataclass
class InferenceTask:
    """æ¨ç†ä»»åŠ¡å°è£…"""
    task_id: int
    rgb_frame: Any
    depth_frame: Optional[Any]
    face_bbox: Optional[Dict]
    face_roi: Optional[Any]
    face_present: bool
    face_just_appeared: bool
    frame_count: int
    global_frame_interval: float
    global_fps: float
    submit_time: float
    person_roi: Optional[Any] = None  #  æ–°å¢å­—æ®µ
    person_bbox: Optional[Dict] = None  #  æ–°å¢å­—æ®µ
```

---

### 3. InferenceScheduler è°ƒåº¦å™¨æ›´æ–°

**æ–‡ä»¶**: `modules/core/inference_scheduler.py`

#### ä¿®æ”¹ 1: `submit()` æ–¹æ³•ç­¾å

```python
def submit(
    self,
    rgb_frame: np.ndarray,
    depth_frame: Optional[np.ndarray],
    face_bbox: Optional[Dict],
    face_roi: Optional[Any],
    face_present: bool,
    face_just_appeared: bool,
    frame_count: int,
    global_frame_interval: float,
    global_fps: float,
    person_roi: Optional[Any] = None,  #  æ–°å¢å‚æ•°
    person_bbox: Optional[Dict] = None  #  æ–°å¢å‚æ•°
):
```

#### ä¿®æ”¹ 2: ä»»åŠ¡åˆ›å»º

```python
task = InferenceTask(
    task_id=self._task_counter,
    rgb_frame=rgb_frame,
    depth_frame=depth_frame,
    face_bbox=face_bbox.copy() if face_bbox is not None else None,
    face_roi=face_roi,
    face_present=face_present,
    face_just_appeared=face_just_appeared,
    frame_count=frame_count,
    global_frame_interval=global_frame_interval,
    global_fps=global_fps,
    submit_time=submit_time,
    person_roi=person_roi,  #  ä¼ é€’ person ROI
    person_bbox=person_bbox.copy() if person_bbox is not None else None  #  ä¼ é€’ person bbox
)
```

#### ä¿®æ”¹ 3: `_infer_pose()` æ–¹æ³•

```python
def _infer_pose(self, task: InferenceTask):
    # ...
    #  ä¼ é€’ person_roi å’Œ person_bboxï¼Œç¡®ä¿åˆ†æåŒä¸€ä¸»è§’
    result = self.pose_engine._run_inference(
        rgb_frame=rgb_frame_copy,
        depth_frame=depth_frame_copy,
        pose_age_ms=pose_age_ms,
        global_frame_interval=task.global_frame_interval,
        frame_count=task.frame_count,
        global_fps=task.global_fps,
        person_roi=task.person_roi,  #  ä½¿ç”¨ä¸»è§’çš„ person ROI
        person_bbox=task.person_bbox  #  ä½¿ç”¨ä¸»è§’çš„ person bbox
    )
```

---

### 4. DetectionOrchestrator é›†æˆ

**æ–‡ä»¶**: `modules/core/orchestrator.py`

#### åŒæ­¥æ¨¡å¼

```python
# å§¿æ€æ£€æµ‹ï¼ˆä½¿ç”¨ PoseEngineï¼‰
#  ä¼ é€’ person_roi å’Œ person_bboxï¼Œç¡®ä¿åˆ†æåŒä¸€ä¸»è§’
pose_results = None
if self.pose_engine:
    pose_result = self.pose_engine.maybe_infer(
        rgb_frame=rgb_frame,
        depth_frame=depth_frame,
        face_present=current_face_detected,
        global_frame_interval=self.global_frame_interval,
        frame_count=self.system.frame_count,
        global_fps=self.global_fps,
        person_roi=person_roi,  #  ä½¿ç”¨ä¸»è§’çš„ person ROI
        person_bbox=person_bbox  #  ä½¿ç”¨ä¸»è§’çš„ person bbox
    )
    pose_results = pose_result.data
```

#### å¼‚æ­¥æ¨¡å¼

```python
if self.async_enabled and self.inference_scheduler:
    # å¼‚æ­¥æ¨¡å¼ï¼šæäº¤ä»»åŠ¡åˆ°è°ƒåº¦å™¨
    self.inference_scheduler.submit(
        rgb_frame=rgb_frame,
        depth_frame=depth_frame,
        face_bbox=face_bbox,
        face_roi=face_roi,
        face_present=current_face_detected,
        face_just_appeared=face_appeared,
        frame_count=self.system.frame_count,
        global_frame_interval=self.global_frame_interval,
        global_fps=self.global_fps,
        person_roi=person_roi,  #  ä¼ é€’ person ROI
        person_bbox=person_bbox  #  ä¼ é€’ person bbox
    )
```

---

## ğŸ¯ å®æ–½æ•ˆæœ

### 1. ä¸€è‡´æ€§ä¿éšœ

**æ‰€æœ‰æ¨¡å—ç°åœ¨åˆ†æåŒä¸€ä¸ªä¸»è§’**:

```python
# orchestrator.py ä¸»å¾ªç¯
target_state = target_manager.update(face_person_pairs, depth_info)

if target_state and target_state.is_valid():
    # æå–åŒä¸€ä¸»è§’çš„åŒ ROI
    rois = roi_manager.extract_dual(
        rgb_frame,
        face_bbox=target_state.face_bbox.to_dict(),
        person_bbox=target_state.person_bbox.to_dict() if target_state.person_bbox else None
    )
    face_roi = rois['face_roi']
    person_roi = rois['person_roi']

    # æ‰€æœ‰æ¨¡å—ä½¿ç”¨ç›¸åŒä¸»è§’çš„ ROI
    emotion_engine.maybe_infer(..., face_roi=face_roi)  # ä¸»è§’Açš„è„¸
    fatigue_engine.infer(..., face_roi=face_roi)        # ä¸»è§’Açš„è„¸
    pose_engine.maybe_infer(..., person_roi=person_roi) # ä¸»è§’Açš„èº«ä½“ âœ…
```

### 2. è°ƒè¯•æ—¥å¿—

å¯ç”¨è°ƒè¯•æ¨¡å¼æŸ¥çœ‹ ROI ä½¿ç”¨æƒ…å†µ:

```bash
export AITABLE_DEBUG_POSE=1
```

**æ—¥å¿—ç¤ºä¾‹**:

```
[Pose] ä½¿ç”¨å¤–éƒ¨ person_roi (offset_x=120, offset_y=80)
[Pose] å…³é”®ç‚¹åæ ‡å·²è½¬æ¢åˆ°å…¨å¸§åæ ‡ç³» (offset: +120, +80)
```

### 3. å‘åå…¼å®¹

**å¦‚æœä¸æä¾› person_roi**: PoseEngine è‡ªåŠ¨å›é€€åˆ°ä¼ ç»Ÿæ¨¡å¼ï¼ˆå…¨å¸§æ£€æµ‹ï¼‰

```python
# ä¼ ç»Ÿè°ƒç”¨ï¼ˆä»ç„¶æœ‰æ•ˆï¼‰
pose_result = pose_engine.maybe_infer(
    rgb_frame=rgb_frame,
    depth_frame=depth_frame,
    face_present=True,
    global_frame_interval=0.033,
    frame_count=100,
    global_fps=30.0
    # ä¸ä¼ é€’ person_roi/person_bbox â†’ è‡ªåŠ¨ä½¿ç”¨å…¨å¸§æ£€æµ‹
)
```

---

## ğŸ§ª æµ‹è¯•å»ºè®®

### 1. å•äººåœºæ™¯æµ‹è¯•

- **é¢„æœŸ**: æ‰€æœ‰æ¨¡å—çš„ `target_id` ä¸€è‡´
- **éªŒè¯**: æ£€æŸ¥æ—¥å¿—ä¸­çš„ `[INCONSISTENT_TARGET]` å‘Šè­¦ï¼ˆåº”è¯¥ä¸º 0ï¼‰

### 2. å¤šäººåœºæ™¯æµ‹è¯•

- **æ“ä½œ**: ä¸»è§’å‰æ–¹æœ‰èƒŒæ™¯äººå‘˜èµ°è¿‡
- **é¢„æœŸ**:
  - Face-Person å…³è”æ­£ç¡®åŒ¹é…ä¸»è§’çš„ face å’Œ person
  - å§¿æ€æ£€æµ‹ä½¿ç”¨ä¸»è§’çš„ person_roiï¼Œå¿½ç•¥èƒŒæ™¯äººå‘˜
  - èƒŒæ™¯äººå‘˜æ·±åº¦è¶…å‡º `[depth_min, depth_max]`ï¼Œä¸ä¼šè¢«é€‰ä¸ºä¸»è§’

### 3. ROI æ¨¡å¼æ—¥å¿—éªŒè¯

```bash
# å¯ç”¨ pose è°ƒè¯•æ—¥å¿—
export AITABLE_DEBUG_POSE=1

# è¿è¡Œç³»ç»Ÿ
python main_gui.py

# æ£€æŸ¥æ—¥å¿—
grep "\[Pose\] ä½¿ç”¨å¤–éƒ¨ person_roi" logs/aitable_*.log
```

**æœŸæœ›è¾“å‡º**:

```
[Pose] ä½¿ç”¨å¤–éƒ¨ person_roi (offset_x=120, offset_y=80)
[Pose] å…³é”®ç‚¹åæ ‡å·²è½¬æ¢åˆ°å…¨å¸§åæ ‡ç³» (offset: +120, +80)
```

### 4. æ€§èƒ½å½±å“æµ‹è¯•

**é¢„æœŸ**: ä½¿ç”¨ person_roi åæ€§èƒ½åº”æœ‰**è½»å¾®æå‡**

- **åŸå› **: åœ¨æ›´å°çš„ ROI ä¸Šæ£€æµ‹ï¼ˆä¾‹å¦‚ 200x400ï¼‰æ¯”å…¨å¸§æ£€æµ‹ï¼ˆ1280x720ï¼‰æ›´å¿«
- **æµ‹è¯•æ–¹æ³•**: æ¯”è¾ƒå§¿æ€æ£€æµ‹å»¶è¿Ÿï¼ˆ`latency_ms`ï¼‰

```bash
# æŸ¥çœ‹å§¿æ€æ€§èƒ½æ—¥å¿—
grep "ã€å§¿æ€æ€§èƒ½åˆ†æã€‘" logs/aitable_*.log
```

---

## ğŸ› å·²çŸ¥é™åˆ¶

1. **ROI è¾¹ç•Œå¤„ç†**: å¦‚æœ person_bbox ç´§è´´å›¾åƒè¾¹ç¼˜ï¼Œå¯èƒ½è£å‰ªä¸å®Œæ•´
   - **è§£å†³**: ROIManager å·²æœ‰è¾¹ç•Œæ£€æŸ¥å’Œ padding å¤„ç†

2. **åæ ‡ç²¾åº¦**: ä» ROI åæ ‡è½¬æ¢å›å…¨å¸§åæ ‡æ—¶ï¼Œé‡‡ç”¨æ•´æ•°åç§»
   - **å½±å“**: å¯å¿½ç•¥ï¼ˆè¯¯å·® < 1 åƒç´ ï¼‰

3. **person_roi ä¸º None**: å¦‚æœ Face-Person å…³è”å¤±è´¥ï¼ˆæœªæ‰¾åˆ°åŒ¹é…çš„ personï¼‰
   - **è¡Œä¸º**: PoseEngine è‡ªåŠ¨å›é€€åˆ°å…¨å¸§æ£€æµ‹æ¨¡å¼

---

## ğŸ“Š æ•°æ®æµæ€»è§ˆ

```
æ¯å¸§å¤„ç†æµç¨‹:
1. äººè„¸æ£€æµ‹ï¼ˆè·å–æ‰€æœ‰äººè„¸ï¼‰
   â†“
2. äººä½“æ£€æµ‹ï¼ˆè·å–æ‰€æœ‰ person bboxï¼‰
   â†“
3.  Face-Person å…³è”ï¼ˆassociate_face_and_personï¼‰
   - è¾“å‡º: face_person_pairs (æ¯ä¸ª face å¯¹åº”ä¸€ä¸ª person)
   â†“
4. TargetPersonManager.update(face_person_pairs)
   - é€‰æ‹©ä¸»è§’ï¼ˆæ·±åº¦ gating + è·Ÿè¸ªè¿ç»­æ€§ï¼‰
   - è¾“å‡º: target_state (åŒ…å« face_bbox + person_bbox)
   â†“
5. ROIManager.extract_dual()
   - è¾“å…¥: target_state.face_bbox, target_state.person_bbox
   - è¾“å‡º: face_roi, person_roi
   â†“
6. å„æ¨¡å—æ¨ç†ï¼ˆä½¿ç”¨ç›¸åŒä¸»è§’çš„ ROIï¼‰
   - æƒ…ç»ª: emotion_engine.maybe_infer(face_roi)
   - ç–²åŠ³: fatigue_engine.infer(face_roi)
   - å§¿æ€: pose_engine.maybe_infer(person_roi, person_bbox) 
   â†“
7. ç»“æœåˆå¹¶ï¼ˆæ‰€æœ‰æ¨¡å—çš„ target_id ä¸€è‡´ï¼‰
```

---

## ğŸš€ æœªæ¥ä¼˜åŒ–æ–¹å‘

1. **æ™ºèƒ½é™çº§ç­–ç•¥**: å½“ person_roi æå–å¤±è´¥æ—¶ï¼Œæ ¹æ®ç½®ä¿¡åº¦å†³å®šæ˜¯å¦å›é€€åˆ°å…¨å¸§æ£€æµ‹

2. **ROI è´¨é‡è¯„ä¼°**: æ£€æŸ¥ person_roi æ˜¯å¦åŒ…å«å®Œæ•´çš„èº«ä½“å…³é”®ç‚¹ï¼ˆè‚©è†€ã€è‡€éƒ¨ç­‰ï¼‰

3. **å¤šäººå§¿æ€æ”¯æŒ**: æ‰©å±•åˆ°æ”¯æŒå¤šä¸ª person_roiï¼ˆç”¨äºå¤šç›®æ ‡è·Ÿè¸ªåœºæ™¯ï¼‰

4. **æ€§èƒ½ç›‘æ§**: åœ¨ TelemetryBuilder ä¸­è®°å½• ROI ä½¿ç”¨ç‡å’Œæ€§èƒ½å¯¹æ¯”

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [ä¸»è§’äººç‰©ç®¡ç†ç³»ç»Ÿ - Face-Person å…³è”å¢å¼ºç‰ˆ](TARGET_PERSON_IMPLEMENTATION.md)
- [TensorRT-Only æ¶æ„è¯´æ˜](TENSORRT_ONLY_ARCHITECTURE.md)
- [æ¶æ„å†³ç­–è®°å½•](ARCHITECTURE_DECISION_ORCHESTRATOR.md)

---

## âœ… å®æ–½æ¸…å•

- [x] ä¿®æ”¹ PoseEngine.maybe_infer() æ¥å£ï¼ˆæ·»åŠ  person_roi/person_bbox å‚æ•°ï¼‰
- [x] ä¿®æ”¹ PoseEngine._run_inference() å®ç°ï¼ˆæ”¯æŒ ROI æ¨¡å¼ + åæ ‡è½¬æ¢ï¼‰
- [x] æ›´æ–° InferenceTask æ•°æ®ç»“æ„ï¼ˆæ·»åŠ  person_roi/person_bbox å­—æ®µï¼‰
- [x] æ›´æ–° InferenceScheduler.submit() æ¥å£
- [x] æ›´æ–° InferenceScheduler._infer_pose() å®ç°
- [x] æ›´æ–° DetectionOrchestratorï¼ˆåŒæ­¥æ¨¡å¼ï¼‰
- [x] æ›´æ–° DetectionOrchestratorï¼ˆå¼‚æ­¥æ¨¡å¼ï¼‰
- [x] ç¼–å†™å®æ–½æ–‡æ¡£

---

**æœ€åæ›´æ–°**: 2025-01-21
**ç‰ˆæœ¬**: v1.0
**çŠ¶æ€**: âœ… å®æ–½å®Œæˆ
